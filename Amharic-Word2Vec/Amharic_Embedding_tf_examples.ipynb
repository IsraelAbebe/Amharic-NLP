{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amharic Embedding tf-examples",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsraelAbebe/Amharic-NLP/blob/master/Amharic-Word2Vec/Amharic_Embedding_tf_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIh3VztMS001",
        "colab_type": "text"
      },
      "source": [
        "# Generating Word Embeddings For Amharic Language\n",
        "\n",
        "## Section  [Using Tensorflow Examples.](https://colab.research.google.com/drive/1aTDUSy8wjA1J07oN2r4Oy12Rgd2yhHDa?authuser=1#scrollTo=V5wlseG_FlDW)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5wlseG_FlDW",
        "colab_type": "text"
      },
      "source": [
        "[TF Examples](https://www.tensorflow.org/tutorials/text/word_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IqZudLvtxb4",
        "colab_type": "code",
        "outputId": "396ea9d0-701f-44ab-caee-181bed1c947a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import unicodedata\n",
        "\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB74RqizzQVE",
        "colab_type": "code",
        "outputId": "e02e45c2-056d-4d3b-892c-3d161bb4f2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re6SvdiJxWms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = layers.Embedding(1000,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-S-LDWczJy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DIRECTORY_URL = \"gdrive/My Drive/dataset/CACO\"\n",
        "FILE_NAMES = ['gdrive/My Drive/dataset/CACO/CACO_TEXT.txt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW4XL6V01P6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def labeler(example, index):\n",
        "  return example, tf.cast(index, tf.int64)  \n",
        "\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return tf.strings.strip(''.join(c for c in unicodedata.normalize('NFD', s.numpy().decode('utf8')) if unicodedata.category(c) != 'Mn'))\n",
        "\n",
        "# Text files\n",
        "files = tf.data.Dataset.list_files(FILE_NAMES, shuffle=True, seed=None)\n",
        "\n",
        "\n",
        "labeled_data_sets = []\n",
        "\n",
        "lines_dataset = tf.data.TextLineDataset(files, compression_type=None, buffer_size=None, num_parallel_reads=None)\n",
        "labeled_dataset = lines_dataset.map(lambda line: labeler(tf.py_function(unicode_to_ascii, [line], tf.string),0))\n",
        "labeled_data_sets.append(labeled_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coH54Z-z4Czr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 50000\n",
        "BATCH_SIZE = 128\n",
        "TAKE_SIZE = 50000\n",
        "\n",
        "\n",
        "all_labeled_data = labeled_data_sets[0]\n",
        "for labeled_dataset in labeled_data_sets[1:]:\n",
        "  all_labeled_data = all_labeled_data.concatenate(labeled_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ioxwCUo4adU",
        "colab_type": "code",
        "outputId": "114c1c39-ca7a-4036-e30b-6a4b5f986d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_labeled_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: (<unknown>, ()), types: (tf.string, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5FgmgIe4kxq",
        "colab_type": "code",
        "outputId": "dcc21ea7-7c91-4e9b-a49b-c463a3ca2d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for ex,_ in all_labeled_data.take(5):\n",
        "  print(ex.numpy().decode('utf8'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "አሁን ወደ ዋናው የጉዞ ፕሮግራም እንመለስ ።\n",
            "ደብዳቤውን ካነበብክ በኋላ \" ጓደኛዬ እኮ እንዲህ አለኝ ! \" ብለህ በደስታ ለሌሎች ትናገር ይሆናል ።\n",
            "የትምህርት ቤቶች እገዛና ድጋፍ ከፍተኛ መሆን እንዳለበትም አስተያየት ሰጥተዋል ።\n",
            "አብደሻል ?\n",
            "ደንብ ካልተከበረ የአዲስ አበባ ከተማን ዕድገት ማሳለጥም አይቻልም ።\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oadl01Mh4omd",
        "colab_type": "code",
        "outputId": "4d89df8b-3e72-45be-8b0c-77ef8de2568e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = tfds.features.text.Tokenizer()\n",
        "\n",
        "vocabulary_set = set()\n",
        "for ex,_ in all_labeled_data:\n",
        "  some_tokens = tokenizer.tokenize(ex.numpy().decode('utf8'))\n",
        "  vocabulary_set.update(some_tokens)\n",
        "\n",
        "vocab_size = len(vocabulary_set)\n",
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "904412"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvy1Xn_29XcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3yQgquDARO2",
        "colab_type": "code",
        "outputId": "8d9780b2-8891-4bbf-9ae3-bf950d833d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_text = next(iter(all_labeled_data))[0].numpy().decode('utf8')\n",
        "print(example_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "አሁን ወደ ዋናው የጉዞ ፕሮግራም እንመለስ ።\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUgL-nGLAVah",
        "colab_type": "code",
        "outputId": "6b8476c3-6a1f-47f4-9610-ac31df457b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoded_example = encoder.encode(example_text)\n",
        "print(encoded_example)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[222004, 338681, 204775, 679989, 429849, 798820]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE-2YvFKAih_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(text_tensor, label):\n",
        "  encoded_text = encoder.encode(text_tensor.numpy().decode('utf8'))\n",
        "  return encoded_text, label\n",
        "\n",
        "def encode_map_fn(text, label):\n",
        "  return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
        "\n",
        "all_encoded_data = all_labeled_data.map(encode_map_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DSAMKmXAudS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)\n",
        "train_data = train_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))\n",
        "\n",
        "test_data = all_encoded_data.take(TAKE_SIZE)\n",
        "test_data = test_data.padded_batch(BATCH_SIZE, padded_shapes=([-1],[]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFXNuYhDPMRP",
        "colab_type": "code",
        "outputId": "dc6a713b-fe6e-4c27-aba9-bb4a875ec228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train_batch, train_labels = next(iter(train_data))\n",
        "train_labels.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDMPt2GUFZvV",
        "colab_type": "text"
      },
      "source": [
        "## Do some Task Directly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEsqYf3WaDjQ",
        "colab_type": "code",
        "outputId": "c46e7387-f988-4959-ef87-eba88e8caf5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "embedding_dim=16\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Embedding(encoder.vocab_size, embedding_dim),\n",
        "  layers.GlobalAveragePooling1D(),\n",
        "  layers.Dense(16, activation='relu'),\n",
        "  layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 16)          14470624  \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 14,470,913\n",
            "Trainable params: 14,470,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP3oGGCK41Y8",
        "colab_type": "code",
        "outputId": "95c31ddf-d17a-4c24-bdb0-790e697cd8e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=10,\n",
        "    validation_data=test_data, validation_steps=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "   2788/Unknown - 662s 238ms/step - loss: 0.0209 - accuracy: 1.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxWzhwdxi8h3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}