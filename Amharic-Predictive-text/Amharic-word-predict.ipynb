{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Jan13",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3W4W4LUt2HIpQh3IVZ19y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsraelAbebe/Amharic-NLP/blob/master/Amharic-Predictive-text/Amharic-word-predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONXoFNGZ00TT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fHPW63W0-zO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = [\"sometimes when you feel buried you are actually just planted\",\n",
        "        \"be still and know that i am God\",\n",
        "        \"god is most glorified when we are most satisfied in him\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moibx9N21wdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "714a5e11-97c8-48bd-8424-1269ce4b1378"
      },
      "source": [
        "chars = set(' '.join(text))\n",
        "print(chars)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'y', 'c', 'o', 'i', 'w', 'd', 'k', 'h', 'm', 'G', 'r', 'n', 's', 'e', 'b', 'u', 'g', ' ', 'j', 'l', 'a', 'p', 'f', 't'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQttMPlB2BV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "0c9f1452-45d2-4f25-f0ce-bb44a11901ca"
      },
      "source": [
        "int2char = dict(enumerate(chars))\n",
        "print(int2char)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'y', 1: 'c', 2: 'o', 3: 'i', 4: 'w', 5: 'd', 6: 'k', 7: 'h', 8: 'm', 9: 'G', 10: 'r', 11: 'n', 12: 's', 13: 'e', 14: 'b', 15: 'u', 16: 'g', 17: ' ', 18: 'j', 19: 'l', 20: 'a', 21: 'p', 22: 'f', 23: 't'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmkX_c7I2QvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "d7871e07-ab1f-4766-b171-c123093a1972"
      },
      "source": [
        "char2int = {int2char[k]:k for k in int2char.keys()}\n",
        "print(char2int)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'y': 0, 'c': 1, 'o': 2, 'i': 3, 'w': 4, 'd': 5, 'k': 6, 'h': 7, 'm': 8, 'G': 9, 'r': 10, 'n': 11, 's': 12, 'e': 13, 'b': 14, 'u': 15, 'g': 16, ' ': 17, 'j': 18, 'l': 19, 'a': 20, 'p': 21, 'f': 22, 't': 23}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta82LOl223XE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d778e99-d996-47e4-aaf1-f567cefacfcb"
      },
      "source": [
        "maxlen = len(max(text,key=len))\n",
        "maxlen"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr7d9udc38e9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2f5dc99d-29d2-4544-8fad-53de0fc609c6"
      },
      "source": [
        "for i in range(len(text)):\n",
        "    while len(text[i]) < maxlen:\n",
        "        text[i] += ' '\n",
        "\n",
        "text"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sometimes when you feel buried you are actually just planted',\n",
              " 'be still and know that i am God                             ',\n",
              " 'god is most glorified when we are most satisfied in him     ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUOSHzY44WWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "964734cd-37d0-45d0-8232-6f1915c4411b"
      },
      "source": [
        "input_sequence = []\n",
        "target_sequence = []\n",
        "\n",
        "for i in range(len(text)):\n",
        "    input_sequence.append(text[i][:-1])\n",
        "    target_sequence.append(text[i][1:])\n",
        "    \n",
        "    print(input_sequence[i],target_sequence[i])"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sometimes when you feel buried you are actually just plante ometimes when you feel buried you are actually just planted\n",
            "be still and know that i am God                             e still and know that i am God                             \n",
            "god is most glorified when we are most satisfied in him     od is most glorified when we are most satisfied in him     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7RRDbwh6ENE",
        "colab_type": "text"
      },
      "source": [
        "One hot mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5TzJnvs5u9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "5395b91c-8ebf-4539-abe6-8200ffd454e8"
      },
      "source": [
        "for i in range(len(text)):\n",
        "    input_sequence[i] = [char2int[character] for character in input_sequence[i]]\n",
        "    target_sequence[i] = [char2int[character] for character in target_sequence[i]]\n",
        "\n",
        "    print(input_sequence[i],target_sequence[i])"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12, 2, 8, 13, 23, 3, 8, 13, 12, 17, 4, 7, 13, 11, 17, 0, 2, 15, 17, 22, 13, 13, 19, 17, 14, 15, 10, 3, 13, 5, 17, 0, 2, 15, 17, 20, 10, 13, 17, 20, 1, 23, 15, 20, 19, 19, 0, 17, 18, 15, 12, 23, 17, 21, 19, 20, 11, 23, 13] [2, 8, 13, 23, 3, 8, 13, 12, 17, 4, 7, 13, 11, 17, 0, 2, 15, 17, 22, 13, 13, 19, 17, 14, 15, 10, 3, 13, 5, 17, 0, 2, 15, 17, 20, 10, 13, 17, 20, 1, 23, 15, 20, 19, 19, 0, 17, 18, 15, 12, 23, 17, 21, 19, 20, 11, 23, 13, 5]\n",
            "[14, 13, 17, 12, 23, 3, 19, 19, 17, 20, 11, 5, 17, 6, 11, 2, 4, 17, 23, 7, 20, 23, 17, 3, 17, 20, 8, 17, 9, 2, 5, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17] [13, 17, 12, 23, 3, 19, 19, 17, 20, 11, 5, 17, 6, 11, 2, 4, 17, 23, 7, 20, 23, 17, 3, 17, 20, 8, 17, 9, 2, 5, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17]\n",
            "[16, 2, 5, 17, 3, 12, 17, 8, 2, 12, 23, 17, 16, 19, 2, 10, 3, 22, 3, 13, 5, 17, 4, 7, 13, 11, 17, 4, 13, 17, 20, 10, 13, 17, 8, 2, 12, 23, 17, 12, 20, 23, 3, 12, 22, 3, 13, 5, 17, 3, 11, 17, 7, 3, 8, 17, 17, 17, 17] [2, 5, 17, 3, 12, 17, 8, 2, 12, 23, 17, 16, 19, 2, 10, 3, 22, 3, 13, 5, 17, 4, 7, 13, 11, 17, 4, 13, 17, 20, 10, 13, 17, 8, 2, 12, 23, 17, 12, 20, 23, 3, 12, 22, 3, 13, 5, 17, 3, 11, 17, 7, 3, 8, 17, 17, 17, 17, 17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzHxfbhS6agD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_size = len(int2char)\n",
        "sequence_len = maxlen - 1\n",
        "batch_size = len(text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTUPPv7m7BJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(sequence,dict_size,sequence_len,batch_size):\n",
        "    features = np.zeros((batch_size,sequence_len,dict_size),dtype=np.float32)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        for u in range(sequence_len):\n",
        "            features[i,u,sequence[i][u]] = 1\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqe3JrhdMO4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "87f655df-306d-440f-a176-f7addc3b818d"
      },
      "source": [
        "dict_size"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qKOy-Qm72zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = one_hot_encode(input_sequence,dict_size,sequence_len,batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "likzeVR08LOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# target_sequence = one_hot_encode(target_sequence,dict_size,sequence_len,batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVEYBpMo8Njw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_seq = torch.from_numpy(input_sequence)\n",
        "target_seq = torch.tensor(target_sequence).squeeze_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_wQSzBx8tH6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "36c71395-e70f-41f2-ea4d-6d52b276adc4"
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "is_cuda"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyIGzZN48-Fc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76b2466b-e61d-46d4-c4fe-bae8826ad9ef"
      },
      "source": [
        "device = torch.device('cuda') if is_cuda else torch.device('cpu')\n",
        "device"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryW6_1oR9T_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self,input_size,output_size,hidden_dim,n_layers):\n",
        "        super(Model,self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.rnn = nn.RNN(input_size,hidden_dim,n_layers,batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim,output_size)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        batch_size = x.size(0)\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "        out,hidden = self.rnn(x,hidden)\n",
        "        out = out.contiguous().view(-1,self.hidden_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out,hidden\n",
        "\n",
        "    def init_hidden(self,batch_size):\n",
        "        hidden = torch.zeros(self.n_layers,batch_size,self.hidden_dim)\n",
        "        return hidden\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzWsCn93_gf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3d97b5ac-6e20-4603-d2b8-82d7881a00dc"
      },
      "source": [
        "model = Model(input_size=dict_size,output_size=dict_size,hidden_dim=12,n_layers=1)\n",
        "model#.to(device)\n",
        "model"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (rnn): RNN(24, 12, batch_first=True)\n",
              "  (fc): Linear(in_features=12, out_features=24, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUzgqFdN_17r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epoches = 1000\n",
        "lr = 0.01\n",
        "\n",
        "criterion  = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDaY-klp__mD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5cbb6f4-1f36-45bc-a380-75df59aa686d"
      },
      "source": [
        "for epoch in range(1,n_epoches+1):\n",
        "    optimizer.zero_grad()\n",
        "    input_seq#.to(device)\n",
        "    output,hidden = model(input_seq)    \n",
        "    loss = criterion(output,target_seq.view(-1).long())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch%10 == 0 :\n",
        "        print('Epoch : {}/{}...'.format(epoch,n_epoches),end=' ')\n",
        "        print(\"Loss: {:.4f}\".format(loss.item()))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 10/1000... Loss: 0.6468\n",
            "Epoch : 20/1000... Loss: 0.5382\n",
            "Epoch : 30/1000... Loss: 0.4443\n",
            "Epoch : 40/1000... Loss: 0.3648\n",
            "Epoch : 50/1000... Loss: 0.3057\n",
            "Epoch : 60/1000... Loss: 0.2602\n",
            "Epoch : 70/1000... Loss: 0.2187\n",
            "Epoch : 80/1000... Loss: 0.1827\n",
            "Epoch : 90/1000... Loss: 0.1833\n",
            "Epoch : 100/1000... Loss: 0.2793\n",
            "Epoch : 110/1000... Loss: 0.1852\n",
            "Epoch : 120/1000... Loss: 0.1457\n",
            "Epoch : 130/1000... Loss: 0.1221\n",
            "Epoch : 140/1000... Loss: 0.1070\n",
            "Epoch : 150/1000... Loss: 0.0950\n",
            "Epoch : 160/1000... Loss: 0.0850\n",
            "Epoch : 170/1000... Loss: 0.0762\n",
            "Epoch : 180/1000... Loss: 0.0683\n",
            "Epoch : 190/1000... Loss: 0.0616\n",
            "Epoch : 200/1000... Loss: 0.2275\n",
            "Epoch : 210/1000... Loss: 0.2158\n",
            "Epoch : 220/1000... Loss: 0.1431\n",
            "Epoch : 230/1000... Loss: 0.1007\n",
            "Epoch : 240/1000... Loss: 0.0786\n",
            "Epoch : 250/1000... Loss: 0.0672\n",
            "Epoch : 260/1000... Loss: 0.0591\n",
            "Epoch : 270/1000... Loss: 0.0530\n",
            "Epoch : 280/1000... Loss: 0.0483\n",
            "Epoch : 290/1000... Loss: 0.0445\n",
            "Epoch : 300/1000... Loss: 0.0413\n",
            "Epoch : 310/1000... Loss: 0.0386\n",
            "Epoch : 320/1000... Loss: 0.0361\n",
            "Epoch : 330/1000... Loss: 0.0339\n",
            "Epoch : 340/1000... Loss: 0.0320\n",
            "Epoch : 350/1000... Loss: 0.0302\n",
            "Epoch : 360/1000... Loss: 0.0287\n",
            "Epoch : 370/1000... Loss: 0.0272\n",
            "Epoch : 380/1000... Loss: 0.0259\n",
            "Epoch : 390/1000... Loss: 0.0246\n",
            "Epoch : 400/1000... Loss: 0.0235\n",
            "Epoch : 410/1000... Loss: 0.0224\n",
            "Epoch : 420/1000... Loss: 0.0215\n",
            "Epoch : 430/1000... Loss: 0.0205\n",
            "Epoch : 440/1000... Loss: 0.0197\n",
            "Epoch : 450/1000... Loss: 0.0189\n",
            "Epoch : 460/1000... Loss: 0.0182\n",
            "Epoch : 470/1000... Loss: 0.0175\n",
            "Epoch : 480/1000... Loss: 0.0168\n",
            "Epoch : 490/1000... Loss: 0.0162\n",
            "Epoch : 500/1000... Loss: 0.0156\n",
            "Epoch : 510/1000... Loss: 0.0151\n",
            "Epoch : 520/1000... Loss: 0.0145\n",
            "Epoch : 530/1000... Loss: 0.0140\n",
            "Epoch : 540/1000... Loss: 0.0136\n",
            "Epoch : 550/1000... Loss: 0.0131\n",
            "Epoch : 560/1000... Loss: 0.0127\n",
            "Epoch : 570/1000... Loss: 0.0123\n",
            "Epoch : 580/1000... Loss: 0.0119\n",
            "Epoch : 590/1000... Loss: 0.0116\n",
            "Epoch : 600/1000... Loss: 0.0112\n",
            "Epoch : 610/1000... Loss: 0.0109\n",
            "Epoch : 620/1000... Loss: 0.0106\n",
            "Epoch : 630/1000... Loss: 0.0103\n",
            "Epoch : 640/1000... Loss: 0.0100\n",
            "Epoch : 650/1000... Loss: 0.0097\n",
            "Epoch : 660/1000... Loss: 0.0095\n",
            "Epoch : 670/1000... Loss: 0.0092\n",
            "Epoch : 680/1000... Loss: 0.0090\n",
            "Epoch : 690/1000... Loss: 0.0087\n",
            "Epoch : 700/1000... Loss: 0.0085\n",
            "Epoch : 710/1000... Loss: 0.0083\n",
            "Epoch : 720/1000... Loss: 0.0081\n",
            "Epoch : 730/1000... Loss: 0.0079\n",
            "Epoch : 740/1000... Loss: 0.0077\n",
            "Epoch : 750/1000... Loss: 0.0075\n",
            "Epoch : 760/1000... Loss: 0.0073\n",
            "Epoch : 770/1000... Loss: 0.0072\n",
            "Epoch : 780/1000... Loss: 0.0070\n",
            "Epoch : 790/1000... Loss: 0.0068\n",
            "Epoch : 800/1000... Loss: 0.0067\n",
            "Epoch : 810/1000... Loss: 0.0065\n",
            "Epoch : 820/1000... Loss: 0.0064\n",
            "Epoch : 830/1000... Loss: 0.0062\n",
            "Epoch : 840/1000... Loss: 0.0061\n",
            "Epoch : 850/1000... Loss: 0.0060\n",
            "Epoch : 860/1000... Loss: 0.0059\n",
            "Epoch : 870/1000... Loss: 0.0057\n",
            "Epoch : 880/1000... Loss: 0.0056\n",
            "Epoch : 890/1000... Loss: 0.0055\n",
            "Epoch : 900/1000... Loss: 0.0054\n",
            "Epoch : 910/1000... Loss: 0.0053\n",
            "Epoch : 920/1000... Loss: 0.0052\n",
            "Epoch : 930/1000... Loss: 0.0051\n",
            "Epoch : 940/1000... Loss: 0.0050\n",
            "Epoch : 950/1000... Loss: 0.0049\n",
            "Epoch : 960/1000... Loss: 0.0048\n",
            "Epoch : 970/1000... Loss: 0.0047\n",
            "Epoch : 980/1000... Loss: 0.0046\n",
            "Epoch : 990/1000... Loss: 0.0045\n",
            "Epoch : 1000/1000... Loss: 0.0044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLa71m3LI58M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model,character):\n",
        "    character = np.array([[char2int[c] for c in character]])\n",
        "    character = one_hot_encode(character,dict_size,character.shape[1],1)\n",
        "    character = torch.from_numpy(character)\n",
        "    \n",
        "    out, hidden = model(character)\n",
        "\n",
        "    prob  = nn.functional.softmax(out[-1],dim=0).data\n",
        "    char_ind = torch.max(prob,dim=0)[1].item()\n",
        "\n",
        "    return int2char[char_ind], hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQXT5hBCOZT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(model,out_len,start='hey'):\n",
        "    model.eval()\n",
        "    start = start.lower()\n",
        "    chars = [i for i in start]\n",
        "    size = out_len-len(chars)\n",
        "\n",
        "    for i in range(size):\n",
        "        char,h = predict(model,chars)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXDr3SsgdMDF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5248c9db-80e1-471f-9a6b-11943af650d1"
      },
      "source": [
        "sample(model, 15, 'what')"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'whatied in mest'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wntpNolwdOdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}